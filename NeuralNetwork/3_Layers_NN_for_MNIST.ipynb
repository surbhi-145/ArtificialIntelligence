{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 Layers NN for MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtnnUFzNGx2lEDS6Y5Vzgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surbhi-145/ArtificialIntelligence/blob/master/NeuralNetwork/3_Layers_NN_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W44WddRcMCUI",
        "colab_type": "text"
      },
      "source": [
        "**Training the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNmhYCBKL_S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.special \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdL8bC1YMiht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "  def __init__(self, inputnodes, hiddennodes,outputnodes,learningrate):\n",
        "    self.inodes = inputnodes\n",
        "    self.hnodes = hiddennodes\n",
        "    self.onodes = outputnodes\n",
        "\n",
        "    self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
        "    self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
        "\n",
        "    self.lr = learningrate\n",
        "    self.activation_function = lambda x : scipy.special.expit(x)\n",
        "    self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
        "    pass\n",
        "\n",
        "  def train(self, inputs_list, targets_list):\n",
        "\n",
        "    inputs = np.array(inputs_list, ndmin =2).T\n",
        "    targets = np.array(targets_list, ndmin= 2).T\n",
        "\n",
        "    hidden_inputs = np.dot(self.wih, inputs)\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "\n",
        "    final_inputs = np.dot(self.who, hidden_outputs)\n",
        "    final_outputs = self.activation_function(final_inputs)\n",
        "\n",
        "    output_errors = targets - final_outputs\n",
        "    hidden_errors = np.dot(self.who.T, output_errors)\n",
        "\n",
        "    self.who += self.lr * np.dot((output_errors * final_outputs * (1.0-final_outputs)), np.transpose(hidden_outputs))\n",
        "    self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0-hidden_outputs)), np.transpose(inputs))\n",
        "    pass\n",
        "  \n",
        "  def query(self, inputs_list):\n",
        "  \n",
        "    inputs = np.array(inputs_list, ndmin=2).T\n",
        "\n",
        "    hidden_inputs = np.dot(self.wih, inputs)\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "\n",
        "    final_inputs = np.dot(self.who, hidden_outputs)\n",
        "    final_outputs = self.activation_function(final_inputs)\n",
        "\n",
        "    return final_outputs\n",
        "  \n",
        "  def backquery(self, targets_list):\n",
        "\n",
        "    final_outputs = np.array(targets_list, ndmin = 2).T\n",
        "    final_inputs = self.inverse_activation_function(final_outputs)\n",
        "\n",
        "    # calculate the signal out of the hidden layer\n",
        "    hidden_outputs = np.dot(self.who.T, final_inputs)\n",
        "    # scale them back to 0.01 to .99\n",
        "    hidden_outputs -= np.min(hidden_outputs)\n",
        "    hidden_outputs /= np.max(hidden_outputs)\n",
        "    hidden_outputs *= 0.98\n",
        "    hidden_outputs += 0.01\n",
        "        \n",
        "    # calculate the signal into the hidden layer\n",
        "    hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
        "        \n",
        "    # calculate the signal out of the input layer\n",
        "    inputs = np.dot(self.wih.T, hidden_inputs)\n",
        "    # scale them back to 0.01 to .99\n",
        "    inputs -= np.min(inputs)\n",
        "    inputs /= np.max(inputs)\n",
        "    inputs *= 0.98\n",
        "    inputs += 0.01\n",
        "        \n",
        "    return inputs\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZrCI7s3RKAo",
        "colab_type": "text"
      },
      "source": [
        "We train our model for each pixel . Therefore input_nodes are 784 (28 x 28) and the output nodes are 10, which is for each digit. The choice for number of nodes in the hidden layer is arbitary. It should be lesser than input nodes, so that we are trying to summarise the feautures in each layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ufdkkWOi6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialise\n",
        "input_nodes = 784\n",
        "hidden_nodes = 200\n",
        "output_nodes = 10\n",
        "learning_rate= 0.1\n",
        "\n",
        "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8flGqTP7PFsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Data \n",
        "training_data_file = open('sample_data/mnist_train_small.csv', 'r')\n",
        "training_data_list = training_data_file.readlines()\n",
        "training_data_file.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Q7qnbAPXyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the Neural Network \n",
        "#epoch is the number of times you train your model \n",
        "epoch = 5\n",
        "for e in range(epoch): \n",
        "  for record in training_data_list:\n",
        "    all_values = record.split(',')\n",
        "    inputs = (np.asfarray(all_values[1:])/255 * 0.99) + 0.01\n",
        "    targets = np.zeros(output_nodes) + 0.01\n",
        "    targets[int(all_values[0])] = 0.99\n",
        "    n.train(inputs,targets)\n",
        "    pass\n",
        "  pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEqwI6NuR5eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test\n",
        "test_data_file = open('mnist_test.csv', 'r')\n",
        "test_data_list = test_data_file.readlines()\n",
        "test_data_file.close()\n",
        "\n",
        "scorecard = []\n",
        "\n",
        "for record in test_data_list:\n",
        "  all_values = record.split(',')\n",
        "  correct_label = int(all_values[0])\n",
        "  inputs = (np.asfarray(all_values[1:])/255 * 0.99) + 0.01\n",
        "  outputs = n.query(inputs)\n",
        "  #index of the highest value\n",
        "  label = np.argmax(outputs)\n",
        "  if label==correct_label:\n",
        "    scorecard.append(1)\n",
        "  else:\n",
        "    scorecard.append(0)\n",
        "  pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM4Dz-BmUNO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "388201b2-04e1-44a0-9004-37f17da1c10f"
      },
      "source": [
        "#Result\n",
        "scorecard_array = np.asarray(scorecard)\n",
        "print(\"Accuracy = \",  scorecard_array.sum() / scorecard_array.size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.9649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVNiyDCPVxdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "ddc0f8be-3206-403b-c2c6-d933228906cc"
      },
      "source": [
        "#Backquery\n",
        "\n",
        "\n",
        "#Run for label 0\n",
        "label = 0\n",
        "# create the output signals for this label\n",
        "targets = np.zeros(output_nodes) + 0.01\n",
        "# all_values[0] is the target label for this record\n",
        "targets[label] = 0.99\n",
        "print(targets)\n",
        "\n",
        "# get image data\n",
        "image_data = n.backquery(targets)\n",
        "\n",
        "# plot image data\n",
        "plt.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa919df4f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}